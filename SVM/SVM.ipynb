{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Chemins vers les dossiers de données d'entraînement et de test\n",
    "train_data_folder = \"D:/UQAC ETE 2023/8INF867_Fondamentaux de l'apprentissage automatique/Projet/FAA_Project/FAA_project/data/train_10000/train_10000\"  # Mettez le bon chemin vers votre dossier de train\n",
    "test_data_folder = \"D:/UQAC ETE 2023/8INF867_Fondamentaux de l'apprentissage automatique/Projet/FAA_Project/FAA_project/data/data\"  # Mettre le bon chemin\n",
    "emotions = [\"anger\", \"disgust\", \"fear\", \"happiness\", \"neutral\", \"sadness\", \"surprise\"]\n",
    "\n",
    "# Prétraitement des données\n",
    "def preprocess_data(data_directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for emotion in emotions:\n",
    "        emotion_path = os.path.join(data_directory, emotion)\n",
    "        for image_name in os.listdir(emotion_path):\n",
    "            image_path = os.path.join(emotion_path, image_name)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Charger l'image en niveaux de gris\n",
    "            image = cv2.resize(image, (48, 48))  # Redimensionner l'image\n",
    "            images.append(image)\n",
    "            labels.append(emotions.index(emotion))  # Étiqueter l'image avec l'indice de l'émotion\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Chargement des données d'entraînement\n",
    "train_images, train_labels = preprocess_data(train_data_folder)\n",
    "\n",
    "# Chargement des données de test\n",
    "test_images, test_labels = preprocess_data(test_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69802, 48, 48)\n",
      "(8000, 2304)\n"
     ]
    }
   ],
   "source": [
    "# Reduce the samples to train\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Determine the desired sample size\n",
    "sample_size = 8000\n",
    "\n",
    "# Convert train_images to a NumPy array\n",
    "train_images_array = np.array(train_images)\n",
    "print(train_images_array.shape)\n",
    "\n",
    "# Reshape train_images_array into a 2D array\n",
    "n_samples = train_images_array.shape[0]\n",
    "train_images_2d = train_images_array.reshape((n_samples, -1))\n",
    "\n",
    "# Convert train_images_2d to DataFrame\n",
    "train_data_df = pd.DataFrame(train_images_2d, columns=[f'feature_{i}' for i in range(train_images_2d.shape[1])])\n",
    "\n",
    "# Perform random sampling while maintaining the same proportion for each class\n",
    "X_train_df, _, y_train, _ = train_test_split(train_data_df, train_labels, train_size=sample_size, stratify=train_labels, random_state=42)\n",
    "\n",
    "# Extract the feature data as a 2D array\n",
    "X_train = X_train_df.values\n",
    "\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2304)\n"
     ]
    }
   ],
   "source": [
    "# Reducing the test set\n",
    "# Determine the desired sample size\n",
    "sample_size = 2000\n",
    "\n",
    "# Convert test_images to a NumPy array\n",
    "test_images_array = np.array(test_images)\n",
    "\n",
    "# Reshape test_images_array into a 2D array\n",
    "n_samples = test_images_array.shape[0]\n",
    "test_images_2d = test_images_array.reshape((n_samples, -1))\n",
    "\n",
    "# Convert test_images_2d to DataFrame\n",
    "test_data_df = pd.DataFrame(test_images_2d, columns=[f'feature_{i}' for i in range(test_images_2d.shape[1])])\n",
    "\n",
    "# Perform random sampling while maintaining the same proportion for each class\n",
    "X_test_df, _, y_test, _ = train_test_split(test_data_df, test_labels, train_size=sample_size, stratify=test_labels, random_state=42)\n",
    "\n",
    "# Extract the feature data as a 2D array\n",
    "X_test = X_test_df.values\n",
    "\n",
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# #############################################################################\n",
    "# Split into a training set and a validation set using a stratified k fold\n",
    "\n",
    "# Define the number of folds\n",
    "k = 5\n",
    "\n",
    "# Initialize the stratified k-fold object\n",
    "skf = StratifiedKFold(n_splits=k, random_state=42, shuffle=True)\n",
    "\n",
    "# Lists to store the training and validation sets\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "\n",
    "# Perform stratified k-fold splitting\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    train_indices.append(train_index)\n",
    "    val_indices.append(val_index)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  0 X_train shape:  (6400, 2304) y_train shape:  (6400,) X_val shape:  (1600, 2304) y_val shape:  (1600,)\n",
      "Shape of train images after PCA:  (6400, 200)\n",
      "Shape of validation images after PCA:  (1600, 200)\n",
      "Shape of test images after PCA:  (2000, 200)\n",
      "Fold:  1 X_train shape:  (6400, 2304) y_train shape:  (6400,) X_val shape:  (1600, 2304) y_val shape:  (1600,)\n",
      "Shape of train images after PCA:  (6400, 200)\n",
      "Shape of validation images after PCA:  (1600, 200)\n",
      "Shape of test images after PCA:  (2000, 200)\n",
      "Fold:  2 X_train shape:  (6400, 2304) y_train shape:  (6400,) X_val shape:  (1600, 2304) y_val shape:  (1600,)\n",
      "Shape of train images after PCA:  (6400, 200)\n",
      "Shape of validation images after PCA:  (1600, 200)\n",
      "Shape of test images after PCA:  (2000, 200)\n",
      "Fold:  3 X_train shape:  (6400, 2304) y_train shape:  (6400,) X_val shape:  (1600, 2304) y_val shape:  (1600,)\n",
      "Shape of train images after PCA:  (6400, 200)\n",
      "Shape of validation images after PCA:  (1600, 200)\n",
      "Shape of test images after PCA:  (2000, 200)\n",
      "Fold:  4 X_train shape:  (6400, 2304) y_train shape:  (6400,) X_val shape:  (1600, 2304) y_val shape:  (1600,)\n",
      "Shape of train images after PCA:  (6400, 200)\n",
      "Shape of validation images after PCA:  (1600, 200)\n",
      "Shape of test images after PCA:  (2000, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Access the data for each fold\n",
    "for fold in range(k):\n",
    "    train_data= np.array(X_train)[train_indices[fold]]\n",
    "    train_labels_fold = np.array(y_train)[train_indices[fold]]\n",
    "    X_val = np.array(X_train)[val_indices[fold]]\n",
    "    val_labels_fold = np.array(y_train)[val_indices[fold]]\n",
    "    print(\"Fold: \",fold, \"X_train shape: \", train_data.shape, \"y_train shape: \", train_labels_fold.shape, \"X_val shape: \", X_val.shape, \"y_val shape: \", val_labels_fold.shape)\n",
    "\n",
    "    # Reshape images into a 2D array\n",
    "    X_train_2d = train_data.reshape((train_data.shape[0], -1))\n",
    "    X_val_2d = X_val.reshape((X_val.shape[0], -1))\n",
    "    X_test_2d = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "    #Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_2d)\n",
    "    X_val_scaled = scaler.transform(X_val_2d)\n",
    "    X_test_scaled = scaler.transform(X_test_2d)\n",
    "\n",
    "    # Compute PCA on the training and validation set\n",
    "    n_components = 200  # Specify the desired number of components\n",
    "    pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True)\n",
    "    X_train_pca = pca.fit_transform(X_train_2d)\n",
    "    X_val_pca = pca.transform(X_val_2d)\n",
    "    X_test_pca = pca.transform(X_test_2d)\n",
    "\n",
    "    # Verify the shape of PCA-transformed images\n",
    "    print(\"Shape of train images after PCA: \", X_train_pca.shape)\n",
    "    print(\"Shape of validation images after PCA: \", X_val_pca.shape)\n",
    "    print(\"Shape of test images after PCA: \", X_test_pca.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found by grid search:\n",
      "{'C': 100, 'gamma': 0.01}\n",
      "Best estimator:\n",
      "SVC(C=100, class_weight='balanced', gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Train a SVM classification model\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='rbf', class_weight='balanced')\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "optimal_params = GridSearchCV(svm, param_grid)\n",
    "optimal_params.fit(X_train_pca, train_labels_fold)\n",
    "# Print the best estimator found by grid search\n",
    "print(\"Best hyperparameters found by grid search:\")\n",
    "print(optimal_params.best_params_)\n",
    "print(\"Best estimator:\")\n",
    "print(optimal_params.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 Accuracy: 0.36125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.42      0.30       230\n",
      "           1       0.44      0.38      0.41       224\n",
      "           2       0.28      0.32      0.30       230\n",
      "           3       0.40      0.31      0.35       229\n",
      "           4       0.44      0.34      0.39       229\n",
      "           5       0.34      0.23      0.27       229\n",
      "           6       0.53      0.52      0.53       229\n",
      "\n",
      "    accuracy                           0.36      1600\n",
      "   macro avg       0.38      0.36      0.36      1600\n",
      "weighted avg       0.38      0.36      0.36      1600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96  35  33  25  14  12  15]\n",
      " [ 60  86  28  17  11  12  10]\n",
      " [ 59  17  74  14  15  22  29]\n",
      " [ 51  20  21  71  26  20  20]\n",
      " [ 40  10  30  23  79  22  25]\n",
      " [ 61  17  47  22  22  52   8]\n",
      " [ 36  10  31   7  13  12 120]]\n",
      "Cohen's Kappa score:  0.25466336783493204\n",
      "Fold: 2 Accuracy: 0.36125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.42      0.30       230\n",
      "           1       0.44      0.38      0.41       224\n",
      "           2       0.28      0.32      0.30       230\n",
      "           3       0.40      0.31      0.35       229\n",
      "           4       0.44      0.34      0.39       229\n",
      "           5       0.34      0.23      0.27       229\n",
      "           6       0.53      0.52      0.53       229\n",
      "\n",
      "    accuracy                           0.36      1600\n",
      "   macro avg       0.38      0.36      0.36      1600\n",
      "weighted avg       0.38      0.36      0.36      1600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96  35  33  25  14  12  15]\n",
      " [ 60  86  28  17  11  12  10]\n",
      " [ 59  17  74  14  15  22  29]\n",
      " [ 51  20  21  71  26  20  20]\n",
      " [ 40  10  30  23  79  22  25]\n",
      " [ 61  17  47  22  22  52   8]\n",
      " [ 36  10  31   7  13  12 120]]\n",
      "Cohen's Kappa score:  0.25466336783493204\n",
      "Fold: 3 Accuracy: 0.36125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.42      0.30       230\n",
      "           1       0.44      0.38      0.41       224\n",
      "           2       0.28      0.32      0.30       230\n",
      "           3       0.40      0.31      0.35       229\n",
      "           4       0.44      0.34      0.39       229\n",
      "           5       0.34      0.23      0.27       229\n",
      "           6       0.53      0.52      0.53       229\n",
      "\n",
      "    accuracy                           0.36      1600\n",
      "   macro avg       0.38      0.36      0.36      1600\n",
      "weighted avg       0.38      0.36      0.36      1600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96  35  33  25  14  12  15]\n",
      " [ 60  86  28  17  11  12  10]\n",
      " [ 59  17  74  14  15  22  29]\n",
      " [ 51  20  21  71  26  20  20]\n",
      " [ 40  10  30  23  79  22  25]\n",
      " [ 61  17  47  22  22  52   8]\n",
      " [ 36  10  31   7  13  12 120]]\n",
      "Cohen's Kappa score:  0.25466336783493204\n",
      "Fold: 4 Accuracy: 0.36125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.42      0.30       230\n",
      "           1       0.44      0.38      0.41       224\n",
      "           2       0.28      0.32      0.30       230\n",
      "           3       0.40      0.31      0.35       229\n",
      "           4       0.44      0.34      0.39       229\n",
      "           5       0.34      0.23      0.27       229\n",
      "           6       0.53      0.52      0.53       229\n",
      "\n",
      "    accuracy                           0.36      1600\n",
      "   macro avg       0.38      0.36      0.36      1600\n",
      "weighted avg       0.38      0.36      0.36      1600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96  35  33  25  14  12  15]\n",
      " [ 60  86  28  17  11  12  10]\n",
      " [ 59  17  74  14  15  22  29]\n",
      " [ 51  20  21  71  26  20  20]\n",
      " [ 40  10  30  23  79  22  25]\n",
      " [ 61  17  47  22  22  52   8]\n",
      " [ 36  10  31   7  13  12 120]]\n",
      "Cohen's Kappa score:  0.25466336783493204\n",
      "Fold: 5 Accuracy: 0.36125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.42      0.30       230\n",
      "           1       0.44      0.38      0.41       224\n",
      "           2       0.28      0.32      0.30       230\n",
      "           3       0.40      0.31      0.35       229\n",
      "           4       0.44      0.34      0.39       229\n",
      "           5       0.34      0.23      0.27       229\n",
      "           6       0.53      0.52      0.53       229\n",
      "\n",
      "    accuracy                           0.36      1600\n",
      "   macro avg       0.38      0.36      0.36      1600\n",
      "weighted avg       0.38      0.36      0.36      1600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96  35  33  25  14  12  15]\n",
      " [ 60  86  28  17  11  12  10]\n",
      " [ 59  17  74  14  15  22  29]\n",
      " [ 51  20  21  71  26  20  20]\n",
      " [ 40  10  30  23  79  22  25]\n",
      " [ 61  17  47  22  22  52   8]\n",
      " [ 36  10  31   7  13  12 120]]\n",
      "Cohen's Kappa score:  0.25466336783493204\n",
      "Mean Accuracy: 0.36125\n"
     ]
    }
   ],
   "source": [
    "#Computing the SVM model with the best parameters obtained\n",
    "from sklearn.metrics import accuracy_score\n",
    "# List to save the model performance for each fold\n",
    "accuracy_scores = []\n",
    "# SVM model training on each fold\n",
    "for fold in range(k):\n",
    "    # Creation, training and evaluation for the current fold\n",
    "    clf_svm = SVC(C= 100,kernel=\"rbf\",gamma = 0.01)\n",
    "    clf_svm.fit(X_train_pca,train_labels_fold)\n",
    "\n",
    "    y_pred_fold = clf_svm.predict(X_val_pca)\n",
    "    accuracy = accuracy_score(val_labels_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Accuracy score for the current fold\n",
    "    print(\"Fold:\", fold+1, \"Accuracy:\", accuracy)\n",
    "\n",
    "    # Evaluate the model for the current fold\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(val_labels_fold, y_pred_fold))\n",
    "\n",
    "    # Print confusion matrix for the current fold\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(val_labels_fold, y_pred_fold))\n",
    "\n",
    "    # Print Cohen's Kappa score for the current fold\n",
    "    print(\"Cohen's Kappa score: \", cohen_kappa_score(val_labels_fold, y_pred_fold))\n",
    "# Mean accuracy for all the folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the model object\n",
    "model_svm = 'svm_model_1.pkl'\n",
    "with open(model_svm, 'wb') as file:\n",
    "    pickle.dump(clf_svm, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_svm = 'svm_model_1.pkl'\n",
    "with open(model_svm, 'rb') as file:\n",
    "    loaded_svm = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on the test set\n",
      "done in 2.810s\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.43      0.30       286\n",
      "           1       0.54      0.45      0.49       286\n",
      "           2       0.31      0.31      0.31       286\n",
      "           3       0.50      0.39      0.44       285\n",
      "           4       0.35      0.37      0.36       286\n",
      "           5       0.37      0.27      0.31       286\n",
      "           6       0.65      0.51      0.57       285\n",
      "\n",
      "    accuracy                           0.39      2000\n",
      "   macro avg       0.42      0.39      0.40      2000\n",
      "weighted avg       0.42      0.39      0.40      2000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122  17  40  25  42  26  14]\n",
      " [ 68 130  21  14  26  16  11]\n",
      " [ 81  32  89  17  22  25  20]\n",
      " [ 58  22  30 110  33  21  11]\n",
      " [ 66  16  26  27 107  30  14]\n",
      " [ 90  13  37  16  45  76   9]\n",
      " [ 33  10  42  10  33  13 144]]\n",
      "Cohen's Kappa score:  0.2871397561924629\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on the test set\n",
    "\n",
    "print(\"Predicting on the test set\")\n",
    "t0 = time()\n",
    "y_pred = loaded_svm.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print Cohen's Kappa score\n",
    "print(\"Cohen's Kappa score: \", cohen_kappa_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File history_dict_svm1 saved\n"
     ]
    }
   ],
   "source": [
    "# Saving the metrics of the model in a dictionary\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "def save_element(x, name=\"element\", binary=True, ext=\".pkl\"):\n",
    "    if binary:\n",
    "        mode = 'wb'\n",
    "        encod='_bin'\n",
    "    else:\n",
    "        encod=\"\"\n",
    "        mode = 'w'\n",
    "    file = open(name +encod + ext, mode)\n",
    "    pickle.dump(x, file)\n",
    "    file.close()\n",
    "    print(\"File \"+name+\" saved\")\n",
    "\n",
    "hist = {\n",
    "    'test_accuracy': accuracy_score(y_test, y_pred),\n",
    "    'test_report': classification_report(y_test, y_pred, output_dict=False, target_names=emotions),\n",
    "    'test_report_dict': classification_report(y_test, y_pred, output_dict=True, target_names=emotions),\n",
    "    'test_cf_matrix': confusion_matrix(y_test, y_pred),\n",
    "    'test_kappa': cohen_kappa_score(y_test, y_pred)}\n",
    "\n",
    "save_element(hist, \"history_dict_svm1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
